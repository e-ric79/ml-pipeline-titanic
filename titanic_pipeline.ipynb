{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuqkvagpYe1Y"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploads=files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ml pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#ml libraries\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "import joblib\n",
        "#settings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "print(\"libraries loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwTEs9x5ZGoz",
        "outputId": "e7893813-0c11-4a23-a57a-cc15fb1b78a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "libraries loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#step 1. data loading and exploration\n",
        "df=pd.read_csv('Titanic-Dataset.csv')\n",
        "print(\"=\"*60)\n",
        "print(\"STEP 1: DATA EXPLORARION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "#basic info\n",
        "print(f\"\\nData shape: {df.shape}\")\n",
        "print(f\"Features: {df.shape[1]}\")\n",
        "print(f\"Samples: {df.shape[0]}\")\n",
        "\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\nMissing Values:\")\n",
        "missing=df.isnull().sum()\n",
        "print(missing[missing>0].sort_values(ascending=False))\n",
        "\n",
        "print(\"\\nTarget Variable Distribution:\")\n",
        "print(df['Survived'].value_counts())\n",
        "print(f\"Survival rate: {df['Survived'].mean():.2%}\")\n",
        "#visualize target\n",
        "fig, ax=plt.subplots(1,2,figsize=(12,4))\n",
        "df['Survived'].value_counts().plot(kind='bar',ax=ax[0],color=['red','green'])\n",
        "ax[0].set_title('Survival Distribution')\n",
        "ax[0].set_xticklabels(['Died','Survived'],rotation=0)\n",
        "ax[0].set_ylabel('Count')\n",
        "\n",
        "df.groupby('Pclass')['Survived'].mean().plot(kind='bar',ax=ax[1])\n",
        "ax[1].set_title('Survival Rate by Class')\n",
        "ax[1].set_ylabel('Survival Rate')\n",
        "ax[1].set_xticklabels(['1st','2nd','3rd'],rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "q8Zynz9kaWfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 2: Data Cleaning\n",
        "print(\"=\"*60)\n",
        "print(\"STEP 2: DATA CLEANING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "#creating clean dataframe\n",
        "df_clean=df.copy()\n",
        "\n",
        "#selecting relevant features\n",
        "features_to_keep=['Survived','Pclass','Sex','Age','SibSp','Parch','Fare']\n",
        "df_clean=df_clean[features_to_keep]\n",
        "\n",
        "print(f\"Features selected: {len(features_to_keep)-1}\")\n",
        "\n",
        "#handle missing values\n",
        "print(\"\\nHandling missing values:\")\n",
        "print(f\"Age missing: {df_clean['Age'].isnull().sum()}\")\n",
        "\n",
        "df_clean['Age']=df_clean['Age'].fillna(df_clean['Age'].median())\n",
        "\n",
        "print(\"Filled age with median\")\n",
        "\n",
        "#encode categorical\n",
        "print(\"\\nEncoding categorical variables:\")\n",
        "df_clean['Sex']=df_clean['Sex'].map({'male':1,'female':0})\n",
        "print(\"sex encoded: male=1, female=0\")\n",
        "\n",
        "#check for remaining missing values\n",
        "remaining_missing=df_clean.isnull().sum().sum()\n",
        "print(f\"\\nRemaining missing values: {remaining_missing}\")\n",
        "\n",
        "#final shape\n",
        "print(f\"\\nClean dataset shape: {df_clean.shape}\")\n",
        "\n",
        "print(\"\\nStep 2 complete: data cleaned\")"
      ],
      "metadata": {
        "id": "mGeXbOslizWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 3: feature analysis\n",
        "print(\"=\"*60)\n",
        "print(\"Step 3: Feature Analysis\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "#separate features and target\n",
        "X=df_clean.drop('Survived',axis=1)\n",
        "y=df_clean['Survived']\n",
        "\n",
        "print(f\"\\nFeatures (X): {X.shape}\")\n",
        "print(f\"Target (y): {y.shape}\")\n",
        "\n",
        "#correlation analysis\n",
        "correlation=df_clean.corr()['Survived'].drop('Survived').sort_values(ascending=False)\n",
        "print(\"\\n\",correlation)\n",
        "\n",
        "#visualize correlations\n",
        "fig, axes=plt.subplots(1,2, figsize=(14,5))\n",
        "\n",
        "#correlation bar plot\n",
        "correlation.plot(kind='barh',ax=axes[0],color=['green' if x>0 else 'red' for x in correlation])\n",
        "axes[0].set_title('Feature Correlation with Survival')\n",
        "axes[0].set_xlabel('Correlation coefficient')\n",
        "\n",
        "#correlation heatmap\n",
        "sns.heatmap(df_clean.corr(),annot=True,cmap='coolwarm',center=0,ax=axes[1])\n",
        "axes[1].set_title(\"Feature Correlation Matrix\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w0CB-CRHsJRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 4: model selection and comparison\n",
        "print(\"=\"*60)\n",
        "print(\"Step 4: Model Selection And Comparison\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "#split data\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "\n",
        "#define models to compare\n",
        "models={\n",
        "    'Logistic Regression': LogisticRegression(random_state=42,max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42,n_estimators=100)\n",
        "\n",
        "}\n",
        "\n",
        "#trainn and evaluate each\n",
        "results={}\n",
        "\n",
        "print(\"\\nTraining and evaluating models...\\n\")\n",
        "\n",
        "for name,model in models.items():\n",
        "  #train\n",
        "  model.fit(X_train,y_train)\n",
        "\n",
        "  #predict\n",
        "  y_pred=model.predict(X_test)\n",
        "\n",
        "  #evaluate\n",
        "  accuracy=accuracy_score(y_test,y_pred)\n",
        "  results[name]=accuracy\n",
        "\n",
        "  print(f\"{name}:\")\n",
        "  print(f\"Accuracy= {accuracy:.4f}\")\n",
        "  print(f\"Classification report:\")\n",
        "  print(classification_report(y_test,y_pred,target_names=['Died','Survived']))\n",
        "  print()\n",
        "\n",
        "#visualize comparison\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(results.keys(),results.values(),color=['blue','orange','green'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Comparison-initial training')\n",
        "plt.ylim(0.75,0.85)\n",
        "\n",
        "for i, (name, acc) in enumerate(results.items()):\n",
        "    plt.text(i, acc + 0.005, f'{acc:.2%}', ha='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "best_model = max(results, key=results.get)\n",
        "print(f\"\\nStep 4 Complete: Best initial model = {best_model} ({results[best_model]:.4f})\")"
      ],
      "metadata": {
        "id": "NxWI0tki2SN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 5: cross validation\n",
        "print(\"=\"*60)\n",
        "print(\"Step 5: Cross validation\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nPerforming 5-fold cross validation on all models\\n\")\n",
        "\n",
        "cv_results={}\n",
        "\n",
        "for name,model in models.items():\n",
        "  #5-fold cv\n",
        "  cv_scores=cross_val_score(model,X,y,cv=5,scoring='accuracy')\n",
        "  cv_results[name]=cv_scores\n",
        "\n",
        "  print(f\"{name}:\")\n",
        "  print(f\"  CV Scores: {cv_scores}\")\n",
        "  print(f\"  Mean: {cv_scores.mean():.4f}\")\n",
        "  print(f\"  Std: {cv_scores.std():.4f}\")\n",
        "  print(f\"  Range: {cv_scores.min():.4f} - {cv_scores.max():.4f}\")\n",
        "  print()\n",
        "\n",
        "# Visualize CV results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Box plot\n",
        "cv_df = pd.DataFrame(cv_results)\n",
        "cv_df.plot(kind='box', ax=axes[0])\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].set_title('Cross-Validation Score Distribution')\n",
        "axes[0].axhline(y=0.8, color='r', linestyle='--', alpha=0.3)\n",
        "\n",
        "# Mean with error bars\n",
        "means = [scores.mean() for scores in cv_results.values()]\n",
        "stds = [scores.std() for scores in cv_results.values()]\n",
        "names = list(cv_results.keys())\n",
        "\n",
        "axes[1].bar(range(len(names)), means, yerr=stds, capsize=10,\n",
        "            color=['blue', 'orange', 'green'], alpha=0.7)\n",
        "axes[1].set_xticks(range(len(names)))\n",
        "axes[1].set_xticklabels(names, rotation=15, ha='right')\n",
        "axes[1].set_ylabel('Mean Accuracy')\n",
        "axes[1].set_title('Mean CV Accuracy with Std Dev')\n",
        "axes[1].set_ylim([0.75, 0.85])\n",
        "\n",
        "for i, (mean, std) in enumerate(zip(means, stds)):\n",
        "    axes[1].text(i, mean + std + 0.005, f'{mean:.2%}\\nÂ±{std:.2%}',\n",
        "                ha='center', fontweight='bold', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Best model by CV\n",
        "best_cv_model = max(cv_results, key=lambda x: cv_results[x].mean())\n",
        "best_cv_score = cv_results[best_cv_model].mean()\n",
        "\n",
        "print(f\"Step 5 Complete: Best CV model = {best_cv_model} ({best_cv_score:.4f})\")"
      ],
      "metadata": {
        "id": "HEaJZivsxY1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 6: hyperparameter tuning\n",
        "print(\"=\"*60)\n",
        "print(\"Step 6: Hyperparameter tuning\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nTuning Random Forest(best cv model)\")\n",
        "\n",
        "#define parameter grid\n",
        "param_grid={\n",
        "      'n_estimators':[50,100,200],\n",
        "      'max_depth': [5,10,15,None],\n",
        "      'min_samples_split':[2,5,10],\n",
        "      'min_samples_leaf':[1,2,4]\n",
        "}\n",
        "\n",
        "total_combos=(\n",
        "    len(param_grid['n_estimators'])*\n",
        "    len(param_grid['max_depth'])*\n",
        "    len(param_grid['min_samples_split'])*\n",
        "    len(param_grid['min_samples_leaf'])\n",
        ")\n",
        "\n",
        "print(f\"Testing {total_combos} combinations with 5-fold cv....\")\n",
        "print(\"This may take 1-2 minutes..\\n\")\n",
        "\n",
        "#grid search\n",
        "rf=RandomForestClassifier(random_state=42)\n",
        "grid_search=GridSearchCV(\n",
        "    estimator=rf,\n",
        "    cv=5,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X,y)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Best Hyperparameters found:\")\n",
        "print(\"=\"*60)\n",
        "for param,value in grid_search.best_params_.items():\n",
        "  print(f\"{param}: {value}\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Perfomance Comparison\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Random Forest (default): {cv_results['Random Forest'].mean():.4f}\")\n",
        "print(f\"Random Forest (tuned):   {grid_search.best_score_:.4f}\")\n",
        "print(f\"Improvement: {(grid_search.best_score_ - cv_results['Random Forest'].mean())*100:+.2f}%\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "#save best model\n",
        "best_model_final=grid_search.best_estimator_\n",
        "\n",
        "print(f\"Step 6 complete: Model tuned to {grid_search.best_score_:.4f} accuracy\")"
      ],
      "metadata": {
        "id": "eXr-oWmOYIqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 7: final model evaluation\n",
        "print(\"=\"*60)\n",
        "print(\"Step 7: Final Model Evaluation\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "#train on full dataset, evaluate with cv\n",
        "final_cv_scores=cross_val_score(best_model_final,X,y,cv=5,scoring='accuracy')\n",
        "\n",
        "print(\"\\nFinal model: Tuned Random forest\")\n",
        "print(f\"5-Fold CV Scores: {final_cv_scores}\")\n",
        "print(f\"Mean Accuracy: {final_cv_scores.mean():.4f}\")\n",
        "print(f\"Std Deviation: {final_cv_scores.std():.4f}\")\n",
        "\n",
        "#Train on all data for deployment\n",
        "best_model_final.fit(X,y)\n",
        "\n",
        "#Feature importance\n",
        "feature_importance=pd.DataFrame({\n",
        "    'Features':X.columns,\n",
        "    'Importance':best_model_final.feature_importances_\n",
        "}).sort_values('Importance',ascending=False)\n",
        "\n",
        "print(\"\\nFeature importance rankings:\")\n",
        "print(feature_importance)\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Feature importance\n",
        "feature_importance.plot(x='Features', y='Importance', kind='barh', ax=axes[0], legend=False)\n",
        "axes[0].set_xlabel('Importance Score')\n",
        "axes[0].set_title('Feature Importance in Final Model')\n",
        "\n",
        "# Complete journey\n",
        "journey = {\n",
        "    'Model': ['Logistic\\nRegression', 'Decision\\nTree', 'Random Forest\\n(Default)', 'Random Forest\\n(Tuned)'],\n",
        "    'Accuracy': [cv_results['Logistic Regression'].mean(),\n",
        "                 cv_results['Decision Tree'].mean(),\n",
        "                 cv_results['Random Forest'].mean(),\n",
        "                 grid_search.best_score_]\n",
        "}\n",
        "\n",
        "axes[1].bar(journey['Model'], journey['Accuracy'], color=['blue', 'orange', 'green', 'red'])\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].set_title('Complete Model Development Journey')\n",
        "axes[1].set_ylim([0.75, 0.85])\n",
        "\n",
        "for i, acc in enumerate(journey['Accuracy']):\n",
        "    axes[1].text(i, acc + 0.005, f'{acc:.2%}', ha='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nStep 7 Complete: Final model achieves {final_cv_scores.mean():.4f} accuracy\")"
      ],
      "metadata": {
        "id": "R6g4hykNixas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 7: model persistence\n",
        "print(\"=\"*60)\n",
        "print(\"Step 7: Model Persistence\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "#save the model\n",
        "model_filename='titanic_survival_model.pkl'\n",
        "joblib.dump(best_model_final,model_filename)\n",
        "print(f\"\\nmodel saved as :{model_filename}\")\n",
        "\n",
        "#save feature names\n",
        "feature_names=list(X.columns)\n",
        "joblib.dump(feature_names,'feature_names.pkl')\n",
        "print(\"\\nfeature names saved as: feature_names.pkl\")\n",
        "\n",
        "#test loading the model\n",
        "loaded_model=joblib.load(model_filename)\n",
        "loaded_features=joblib.load('feature_names.pkl')\n",
        "\n",
        "print(\"\\n\"+\"=\"*60)\n",
        "print(\"Model Deployment Test\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "#make a prediction with loaded model\n",
        "sample_passenger=X.iloc[0:1]\n",
        "print(\"\\nSample passenger feature\")\n",
        "print(sample_passenger)\n",
        "\n",
        "prediction=loaded_model.predict(sample_passenger)[0]\n",
        "probability=loaded_model.predict_proba(sample_passenger)[0]\n",
        "\n",
        "print(f\"Prediction: {'Survived' if prediction==1 else 'Died'}\")\n",
        "print(f\"Confidence: {probability[1]:.1%} chance of survival\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PIPELINE COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Final Model: Tuned Random Forest\")\n",
        "print(f\"Accuracy: {grid_search.best_score_:.2%}\")\n",
        "print(f\"Model saved and ready for deployment\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "SsXUJXwQnxmU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}